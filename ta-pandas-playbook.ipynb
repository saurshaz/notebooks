{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5582293b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print('Fine python notebookers >>>>>')\n",
    "\n",
    "\n",
    "NSE_COOKIE = '3E%2FY7AYhc%2Bo0PAYlCyo%2BEN1vXLDvHMyTyoWvUJizZHY4D8Ttn56CIem7GHTYnw1h6ntDP2Xl%2BRcFVRO62gZxWw%2BHSTpqET39nGn6ZhXnclgY1aBtj5xGMu0l1g2rvnF5UrN8CJ3Iz57B12gNQkakXcbjw4ZOXtYsaT4EcJbLB%2FfXiYRxTd8AoFDoaBaTj%2BliL04SP0GSh5rI'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pymongo\n",
    "!pip install arctic\n",
    "from arctic import Arctic\n",
    "\n",
    "import pandas as pd\n",
    "from pymongo import MongoClient\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import yfinance as yf\n",
    "import talib as ta\n",
    "\n",
    "import pandas as pd\n",
    "import pandas_ta as ta\n",
    "from pandas_datareader import data\n",
    "from watchlist import Watchlist # Is this failing? If so, copy it locally. See above.\n",
    "\n",
    "import time\n",
    "import os\n",
    "import datetime as dt\n",
    "from pathlib import Path\n",
    "import shutil \n",
    "\n",
    "# ticker = \"20MICRONS\"\n",
    "home_dir = Path.home()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# filtered_companies = [ 'MUTHOOTFIN.NS', 'MUTHOOTCAP.NS', 'COALINDIA.NS','ICICIPRULI.NS', 'DEEPAKNTR.NS', 'BAJAJELEC.NS', 'BAJAJ-AUTO.NS', 'EICHERMOT.NS', 'EASEMYTRIP.NS', 'BAJFINANCE.NS',  'DMART.NS', 'PERSISTENT.NS', 'IOB.NS', 'IOC.NS', 'IDFCFIRSTB.NS', 'MINDTREE.NS', 'BEL.NS', 'NIFTYBEES.NS', 'JKPAPER.NS', 'NAUKRI.NS', 'EASEMYTRIP.NS', '^NSEBANK', '^NSEI', 'BAJFINANCE.NS', 'BAJFINSV.NS', 'SBILIFE.NS', 'HDFCLIFE.NS',  'BRITANNIA.NS', 'VOLTAS.NS', 'CAMLINFINE.NS', 'INDHOTEL.NS', 'LEMONTREE.NS', 'GLAXO.NS', 'SUNPHARMA.NS', 'ASIANPAINT.NS', 'PRESTIGE.NS', 'DLF.NS', 'BERGERPAINTS.NS', 'POWERGRID.NS', 'ADANIPORTS.NS', 'ADANIENT.NS', 'DHAMPURSUG.NS', 'SRTRANSFIN.NS', 'GMBREW.NS', 'NUCLEUS.NS', 'CEATLTD.NS', 'ANDHRSUGAR.NS', 'PRAJIND.NS', 'IOC.NS', 'IGL.NS', 'INDIGO.NS', 'PVR.NS', 'LUPIN.NS', 'RBLBANK.NS', 'DEEPAKNITRITE.NS', 'FORCEMOTORS.NS', 'ASTRAL.NS', 'INDUSINDBK.NS', 'MFSL.NS', 'MRF.NS', 'BATAINDIA.NS', 'TATAPOWER.NS', 'MPHASIS.NS', 'SPICEJET.NS', 'INOXLEISUR' ,'NIFTY.NS', 'IBREALEST.NS', 'ASTERDM.NS',  'IBULHSGFIN.NS', 'BANKNIFTY.NS', 'NESTLEIND.NS', 'UBL.NS', 'MCDOWELLS.NS', 'LT.NS', 'LTI.NS', 'LTTS.NS', 'GRASIM.NS', 'RAYMOND.NS', 'ULTRATECHCEM.NS', 'ACC.NS', 'HAVELLS.NS', 'TATACOFFEE.NS', 'TATASTEEL.NS', 'TATAMOTORS.NS', 'ASHOKLEY.NS', 'PNB.NS', 'CANBK.NS', 'BANKBARODA.NS', 'IDFCFIRST.NS', 'TATACHEM.NS', 'HINDUNILVR.NS', 'GODREJPROP.NS', 'SOBHA.NS', 'APOLLOHOSP.NS', 'BEL.NS', 'FORTIS.NS', 'HINDCOPPER.NS', 'HINDZINC.NS',  'BHARTIARTL.NS', 'HCLTECH.NS', 'GAIL.NS', 'ONGC.NS', 'SAIL.NS', 'HINDALCO.NS', 'GLENMARK.NS', 'BPCL.NS', 'HDFCAMC.NS', 'NTPC.NS', 'ZEEL.NS', 'ZOMATO.NS', 'ICICIBANK.NS', 'SBIN.NS', 'IRCTC.NS', 'AXISBANK.NS',  'M&M.NS',  'ITC.NS', 'MARICO.NS', 'INDUSIND.NS', 'TITAN.NS', 'DIVISLAB.NS', 'PFIZER.NS', 'NESTLE.NS', 'PGHH.NS', 'TATACONSUM.NS', 'GODREJCP.NS', 'HAPPSTMNDS.NS', 'SONATASOFTW.NS', 'NAZARA.NS', 'BHEL.NS', 'COFORGE.NS', 'HDFC.NS', 'HDFCBANK.NS', 'KOTAKBANK.NS', 'CIPLA.NS', 'TCS.NS', 'CDSL.NS', 'BSE.NS', 'INFY.NS', 'WIPRO.NS', 'TECHM.NS', 'JSWSTEEL.NS', 'MANAPPURAM.NS', 'DRREDDY.NS']\n",
    "filtered_companies = [ 'MUTHOOTFIN.NS', 'MUTHOOTCAP.NS', 'COALINDIA.NS','ICICIPRULI.NS', 'DEEPAKNTR.NS', 'BAJAJELEC.NS', 'BAJAJ-AUTO.NS', 'EICHERMOT.NS', 'INFY.NS', 'WIPRO.NS', 'TECHM.NS', 'JSWSTEEL.NS', 'MANAPPURAM.NS', 'DRREDDY.NS' ]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def get_oc(ticker):\n",
    "    # Let's get option chain for identified tickers and find the ideal strikes data\n",
    "    url = \"https://www.nseindia.com/api/option-chain-equities\"\n",
    "\n",
    "    querystring = {\"symbol\":ticker}\n",
    "\n",
    "    payload = \"\"\n",
    "    \n",
    "    headers = {'cookie': NSE_COOKIE}\n",
    "\n",
    "    response = requests.request(\"GET\", url, data=payload, headers=headers, params=querystring)\n",
    "    print(response.text)\n",
    "    return response.text\n",
    "\n",
    "\n",
    "    \n",
    "# get_oc('ADANIPORTS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_columns = ['open', 'high', 'low', 'close', 'volume', 'stock splits', 'aber_zg_5_15', 'aber_sg_5_15', 'aber_xg_5_15', 'aber_atr_5_15', 'accbl_20', 'accbm_20', 'accbu_20', 'ad', 'adosc_3_10', '    ', 'dmp_14', 'dmn_14', 'alma_10_6.0_0.85', 'amate_lr_8_21_2', 'amate_sr_8_21_2', 'ao_5_34', 'obv', 'obv_min_2', 'obv_max_2', 'obve_4', 'obve_12', 'aobv_lr_2', 'aobv_sr_2', 'apo_12_26', 'aroond_14', 'aroonu_14', 'aroonosc_14', 'atrr_14', 'bbl_5_2.0', 'bbm_5_2.0', 'bbu_5_2.0', 'bbb_5_2.0', 'bbp_5_2.0', 'bias_sma_26', 'bop', 'ar_26', 'br_26', 'cci_14_0.015', 'cdl_2crows', 'cdl_3blackcrows', 'cdl_3inside', 'cdl_3linestrike', 'cdl_3outside', 'cdl_3starsinsouth', 'cdl_3whitesoldiers', 'cdl_abandonedbaby', 'cdl_advanceblock', 'cdl_belthold', 'cdl_breakaway', 'cdl_closingmarubozu', 'cdl_concealbabyswall', 'cdl_counterattack', 'cdl_darkcloudcover', 'cdl_doji_10_0.1', 'cdl_dojistar', 'cdl_dragonflydoji', 'cdl_engulfing', 'cdl_eveningdojistar', 'cdl_eveningstar', 'cdl_gapsidesidewhite', 'cdl_gravestonedoji', 'cdl_hammer', 'cdl_hangingman', 'cdl_harami', 'cdl_haramicross', 'cdl_highwave', 'cdl_hikkake', 'cdl_hikkakemod', 'cdl_homingpigeon', 'cdl_identical3crows', 'cdl_inneck', 'cdl_inside', 'cdl_invertedhammer', 'cdl_kicking', 'cdl_kickingbylength', 'cdl_ladderbottom', 'cdl_longleggeddoji', 'cdl_longline', 'cdl_marubozu', 'cdl_matchinglow', 'cdl_mathold', 'cdl_morningdojistar', 'cdl_morningstar', 'cdl_onneck', 'cdl_piercing', 'cdl_rickshawman', 'cdl_risefall3methods', 'cdl_separatinglines', 'cdl_shootingstar', 'cdl_shortline', 'cdl_spinningtop', 'cdl_stalledpattern', 'cdl_sticksandwich', 'cdl_takuri', 'cdl_tasukigap', 'cdl_thrusting', 'cdl_tristar', 'cdl_unique3river', 'cdl_upsidegap2crows', 'cdl_xsidegap3methods', 'open_z_30_1', 'high_z_30_1', 'low_z_30_1', 'close_z_30_1', 'cfo_9', 'cg_10', 'chop_14_1_100', 'ckspl_10_3_20', 'cksps_10_3_20', 'cmf_20', 'cmo_14', 'copc_11_14_10', 'cti_12', 'ldecay_5', 'dec_1', 'dema_10', 'dcl_20_20', 'dcm_20_20', 'dcu_20_20', 'dpo_20', 'ebsw_40_10', 'efi_13', 'ema_10', 'entp_10', 'eom_14_100000000', 'er_10', 'bullp_13', 'bearp_13', 'fishert_9_1', 'fisherts_9_1', 'fwma_10', 'ha_open', 'ha_high', 'ha_low', 'ha_close', 'hilo_13_21', 'hilol_13_21', 'hilos_13_21', 'hl2', 'hlc3', 'hma_10', 'hwm', 'hwu', 'hwl', 'hwma_0.2_0.1_0.1', 'isa_9', 'isb_26', 'its_9', 'iks_26', 'ics_26', 'inc_1', 'inertia_20_14', 'jma_7_0', 'kama_10_2_30', 'kcle_20_2', 'kcbe_20_2', 'kcue_20_2', 'k_9_3', 'd_9_3', 'j_9_3', 'kst_10_15_20_30_10_10_10_15', 'ksts_9', 'kurt_30', 'kvo_34_55_13', 'kvos_34_55_13', 'lr_14', 'logret_1', 'macd_12_26_9', 'macdh_12_26_9', 'macds_12_26_9', 'mad_30', 'massi_9_25', 'mcgd_10', 'median_30', 'mfi_14', 'midpoint_2', 'midprice_2', 'mom_10', 'natr_14', 'nvi_1', 'ohlc4', 'pdist', 'pctret_1', 'pgo_14', 'ppo_12_26_9', 'ppoh_12_26_9', 'ppos_12_26_9', 'psarl_0.02_0.2', 'psars_0.02_0.2', 'psaraf_0.02_0.2', 'psarr_0.02_0.2', 'psl_12', 'pvi_1', 'pvo_12_26_9', 'pvoh_12_26_9', 'pvos_12_26_9', 'pvol', 'pvr', 'pvt', 'pwma_10', 'qqe_14_5_4.236', 'qqe_14_5_4.236_rsima', 'qqel_14_5_4.236', 'qqes_14_5_4.236', 'qs_10', 'qtl_30_0.5', 'rma_10', 'roc_10', 'rsi_14', 'rsx_14', 'rvgi_14_4', 'rvgis_14_4', 'rvi_14', 'sinwma_14', 'skew_30', 'slope_1', 'sma_10', 'smi_5_20_5', 'smis_5_20_5', 'smio_5_20_5', 'sqz_20_2.0_20_1.5', 'sqz_on', 'sqz_off', 'sqz_no', 'sqzpro_20_2.0_20_2_1.5_1', 'sqzpro_on_wide', 'sqzpro_on_normal', 'sqzpro_on_narrow', 'sqzpro_off', 'sqzpro_no', 'ssf_10_2', 'stc_10_12_26_0.5', 'stcmacd_10_12_26_0.5', 'stcstoch_10_12_26_0.5', 'stdev_30', 'stochk_14_3_3', 'stochd_14_3_3', 'stochrsik_14_14_3_3', 'stochrsid_14_14_3_3', 'supert_7_3.0', 'supertd_7_3.0', 'supertl_7_3.0', 'superts_7_3.0', 'swma_10', 't3_10_0.7', 'tema_10', 'thermo_20_2_0.5', 'thermoma_20_2_0.5', 'thermol_20_2_0.5', 'thermos_20_2_0.5', 'tos_stdevall_lr', 'tos_stdevall_l_1', 'tos_stdevall_u_1', 'tos_stdevall_l_2', 'tos_stdevall_u_2', 'tos_stdevall_l_3', 'tos_stdevall_u_3', 'trima_10', 'trix_30_9', 'trixs_30_9', 'truerange_1', 'tsi_13_25_13', 'tsis_13_25_13', 'ttm_trnd_6', 'ui_14', 'uo_7_14_28', 'var_30', 'vhf_28', 'vidya_14', 'vtxp_14', 'vtxm_14', 'vwap_d', 'vwma_10', 'wcp', 'willr_14', 'wma_10', 'zl_ema_10', 'zs_30']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arctic import Arctic\n",
    "\n",
    "# Connect to Local MONGODB\n",
    "store = Arctic('localhost')\n",
    "\n",
    "# library = store['NSEx']\n",
    "# library.delete({})\n",
    "\n",
    "# Create the library - defaults to VersionStore\n",
    "store.initialize_library('NSEx')\n",
    "# store.delete_library('NSEDATA')\n",
    "\n",
    "library = store['NSEx']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def df_from_db(_ticker, tf):\n",
    "    try:\n",
    "        # _ticker = _ticker.replace('.NS', 'MANAPPURAM.NS_2d')\n",
    "        # print('libraries .. ', store.list_libraries())\n",
    "        print('fetching from local saved DB ticker data  .. ')\n",
    "        # Reading the data\n",
    "        symbol_df = library.read(_ticker + '_' + tf)\n",
    "        _ticker_data = symbol_df.data\n",
    "        print('fetched from local saved DB ticker data  .. ')\n",
    "        # _data =  list(library.query())\n",
    "        # print('ticker data length .. ', len(_ticker_data))\n",
    "        return _ticker_data\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return []\n",
    "\n",
    "def recent_bars(df, tf: str = \"1d\"):\n",
    "    # All Data: 0, Last Four Years: 0.25, Last Two Years: 0.5, This Year: 1, Last Half Year: 2, Last Quarter: 4\n",
    "    yearly_divisor = {\"all\": 0, \"10y\": 0.1, \"5y\": 0.2, \"4y\": 0.25, \"3y\": 1./3, \"2y\": 0.5, \"1y\": 1, \"6mo\": 2, \"3mo\": 4, \"1mo\": 12, \"5d\": 73, \"1d\": 365, \"2d\": 365/2}\n",
    "    yd = yearly_divisor[tf] if tf in yearly_divisor.keys() else 0\n",
    "    return int(ta.RATE[\"TRADING_DAYS_PER_YEAR\"] / yd) if yd > 0 else df.shape[0]\n",
    "\n",
    "def fresh_load(_ticker, duration, tf: str = \"1d\"):\n",
    "    watch = Watchlist([_ticker], tf=tf, ds_name=\"yahoo\", timed=True)\n",
    "    data_source = \"yahoo\"\n",
    "    # If you have a Custom Strategy, you can use it here.\n",
    "    # watch.strategy = ta.CommonStrategy \n",
    "    watch.strategy = ta.AllStrategy\n",
    "    watch.load([_ticker], analyze=True, verbose=False)\n",
    "    asset = watch.data[_ticker]\n",
    "    recent = recent_bars(asset, duration)\n",
    "    asset.columns = asset.columns.str.lower()\n",
    "    asset.drop(columns=[\"dividends\", \"split\"], errors=\"ignore\", inplace=True)\n",
    "    asset = asset.copy().tail(recent)\n",
    "    # # Store the data in the library\n",
    "    library.write(_ticker + '_' + tf , asset, metadata={ 'source': 'custom', 'duration': duration})\n",
    "    return asset\n",
    "\n",
    "## compute all essential TA data points\n",
    "## method to compute all TAs using pandas-ta\n",
    "## TODO: the timeframe being used is 1min, there shall be an option to change that \n",
    "def get_technical_data(_ticker, duration, tf: str = '5min'):\n",
    "    print(' Processing ... ',_ticker)\n",
    "    df = df_from_db(_ticker, tf)\n",
    "    if df is not None:\n",
    "        # import pdb; pdb.set_trace()\n",
    "        if df is not None and len(df) > 0:\n",
    "            df.drop(columns=[\"dividends\", \"split\"], errors=\"ignore\", inplace=True)\n",
    "            return df\n",
    "        else:\n",
    "            return fresh_load(_ticker, duration, tf)\n",
    "    else:\n",
    "        return fresh_load(_ticker, duration, tf)\n",
    "\n",
    "    # # fetch option_chain (for NSE listed symbol)\n",
    "    # option_chain = get_oc(ticker)\n",
    "    # print(option_chain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# compute scores\n",
    "def compute_score(df, _s = 0):\n",
    "    if df['volume'] < 10000:\n",
    "        # LOW VOLUME, -20 from score\n",
    "     _s = _s - 10\n",
    "    if df['volume'] > 10000:\n",
    "        _s = _s + 10\n",
    "    if df['atrr_14']:\n",
    "        _s = _s + (df['atrr_14']/5) - 6\n",
    "    if df['close'] > df['wma_10']:\n",
    "        _s = _s + 10\n",
    "    if df['close'] < df['wma_10']:\n",
    "        _s = _s - 10\n",
    "    return _s\n",
    "\n",
    "df_scores = pd.DataFrame({})\n",
    "filter_criteria = {}\n",
    "\n",
    "# TODO: save and update all of this iterated data to a Mongo DB on each run of this logic (maybe to different tables)\n",
    "# TODO: create a DB query to filter the data on the basis of different filtering criterias and save scores for eachticker at different times\n",
    "# TODO: Simple select query for all data for a ticker for any duration () could help us in plotting the chart with all the tech indicators also (as we have them computed). build an API for same\n",
    "# TODO: make this data be able to run a flashback chart (having that running with echarts is also an option). this already exists\n",
    "# TODO: make backtests run on each ticker and have results saved for each duration in a parallel DB table\n",
    "for _ticker in filtered_companies:\n",
    "    df_scores['symbol'] = _ticker\n",
    "    df_5y = get_technical_data(_ticker, duration='5y', tf='1w')\n",
    "    df_1y = get_technical_data(_ticker, duration='1y', tf='1d')\n",
    "    df_1mo = get_technical_data(_ticker, duration='1mo', tf='1d')\n",
    "    df_5d = get_technical_data(_ticker, duration='5d', tf='1min')\n",
    "    df_2d = get_technical_data(_ticker, duration='3d', tf='1min')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A test of loading in rapid fashion from local DB (earlier saved copy)\n",
    "df_1d = get_technical_data('WIPRO.NS', duration='1y', tf='1d')\n",
    "print('df_1y ... ',df_1d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Empty DataFrame\n",
      "Columns: [ticker, scores_2d, scores_5d, scores_1mo, scores_1y, scores_5y]\n",
      "Index: []\n",
      " Processing ...  MUTHOOTFIN.NS\n",
      "fetching from local saved DB ticker data  .. \n",
      "fetched from local saved DB ticker data  .. \n",
      " Processing ...  MUTHOOTFIN.NS\n",
      "fetching from local saved DB ticker data  .. \n",
      "fetched from local saved DB ticker data  .. \n",
      " Processing ...  MUTHOOTFIN.NS\n",
      "fetching from local saved DB ticker data  .. \n",
      "fetched from local saved DB ticker data  .. \n",
      " Processing ...  MUTHOOTFIN.NS\n",
      "fetching from local saved DB ticker data  .. \n",
      "fetched from local saved DB ticker data  .. \n",
      " Processing ...  MUTHOOTFIN.NS\n",
      "fetching from local saved DB ticker data  .. \n",
      "fetched from local saved DB ticker data  .. \n",
      " Processing ...  MUTHOOTCAP.NS\n",
      "fetching from local saved DB ticker data  .. \n",
      "fetched from local saved DB ticker data  .. \n",
      " Processing ...  MUTHOOTCAP.NS\n",
      "fetching from local saved DB ticker data  .. \n",
      "fetched from local saved DB ticker data  .. \n",
      " Processing ...  MUTHOOTCAP.NS\n",
      "fetching from local saved DB ticker data  .. \n",
      "fetched from local saved DB ticker data  .. \n",
      " Processing ...  MUTHOOTCAP.NS\n",
      "fetching from local saved DB ticker data  .. \n",
      "fetched from local saved DB ticker data  .. \n",
      " Processing ...  MUTHOOTCAP.NS\n",
      "fetching from local saved DB ticker data  .. \n",
      "fetched from local saved DB ticker data  .. \n",
      " Processing ...  COALINDIA.NS\n",
      "fetching from local saved DB ticker data  .. \n",
      "fetched from local saved DB ticker data  .. \n",
      " Processing ...  COALINDIA.NS\n",
      "fetching from local saved DB ticker data  .. \n",
      "fetched from local saved DB ticker data  .. \n",
      " Processing ...  COALINDIA.NS\n",
      "fetching from local saved DB ticker data  .. \n",
      "fetched from local saved DB ticker data  .. \n",
      " Processing ...  COALINDIA.NS\n",
      "fetching from local saved DB ticker data  .. \n",
      "fetched from local saved DB ticker data  .. \n",
      " Processing ...  COALINDIA.NS\n",
      "fetching from local saved DB ticker data  .. \n",
      "fetched from local saved DB ticker data  .. \n",
      " Processing ...  ICICIPRULI.NS\n",
      "fetching from local saved DB ticker data  .. \n",
      "fetched from local saved DB ticker data  .. \n",
      " Processing ...  ICICIPRULI.NS\n",
      "fetching from local saved DB ticker data  .. \n",
      "fetched from local saved DB ticker data  .. \n",
      " Processing ...  ICICIPRULI.NS\n",
      "fetching from local saved DB ticker data  .. \n",
      "fetched from local saved DB ticker data  .. \n",
      " Processing ...  ICICIPRULI.NS\n",
      "fetching from local saved DB ticker data  .. \n",
      "fetched from local saved DB ticker data  .. \n",
      " Processing ...  ICICIPRULI.NS\n",
      "fetching from local saved DB ticker data  .. \n",
      "fetched from local saved DB ticker data  .. \n",
      " Processing ...  DEEPAKNTR.NS\n",
      "fetching from local saved DB ticker data  .. \n",
      "fetched from local saved DB ticker data  .. \n",
      " Processing ...  DEEPAKNTR.NS\n",
      "fetching from local saved DB ticker data  .. \n",
      "fetched from local saved DB ticker data  .. \n",
      " Processing ...  DEEPAKNTR.NS\n",
      "fetching from local saved DB ticker data  .. \n",
      "fetched from local saved DB ticker data  .. \n",
      " Processing ...  DEEPAKNTR.NS\n",
      "fetching from local saved DB ticker data  .. \n",
      "fetched from local saved DB ticker data  .. \n",
      " Processing ...  DEEPAKNTR.NS\n",
      "fetching from local saved DB ticker data  .. \n",
      "fetched from local saved DB ticker data  .. \n",
      " Processing ...  BAJAJELEC.NS\n",
      "fetching from local saved DB ticker data  .. \n",
      "fetched from local saved DB ticker data  .. \n",
      " Processing ...  BAJAJELEC.NS\n",
      "fetching from local saved DB ticker data  .. \n",
      "fetched from local saved DB ticker data  .. \n",
      " Processing ...  BAJAJELEC.NS\n",
      "fetching from local saved DB ticker data  .. \n",
      "fetched from local saved DB ticker data  .. \n",
      " Processing ...  BAJAJELEC.NS\n",
      "fetching from local saved DB ticker data  .. \n",
      "fetched from local saved DB ticker data  .. \n",
      " Processing ...  BAJAJELEC.NS\n",
      "fetching from local saved DB ticker data  .. \n",
      "fetched from local saved DB ticker data  .. \n",
      " Processing ...  BAJAJ-AUTO.NS\n",
      "fetching from local saved DB ticker data  .. \n",
      "fetched from local saved DB ticker data  .. \n",
      " Processing ...  BAJAJ-AUTO.NS\n",
      "fetching from local saved DB ticker data  .. \n",
      "fetched from local saved DB ticker data  .. \n",
      " Processing ...  BAJAJ-AUTO.NS\n",
      "fetching from local saved DB ticker data  .. \n",
      "fetched from local saved DB ticker data  .. \n",
      " Processing ...  BAJAJ-AUTO.NS\n",
      "fetching from local saved DB ticker data  .. \n",
      "fetched from local saved DB ticker data  .. \n",
      " Processing ...  BAJAJ-AUTO.NS\n",
      "fetching from local saved DB ticker data  .. \n",
      "fetched from local saved DB ticker data  .. \n",
      " Processing ...  EICHERMOT.NS\n",
      "fetching from local saved DB ticker data  .. \n",
      "fetched from local saved DB ticker data  .. \n",
      " Processing ...  EICHERMOT.NS\n",
      "fetching from local saved DB ticker data  .. \n",
      "fetched from local saved DB ticker data  .. \n",
      " Processing ...  EICHERMOT.NS\n",
      "fetching from local saved DB ticker data  .. \n",
      "fetched from local saved DB ticker data  .. \n",
      " Processing ...  EICHERMOT.NS\n",
      "fetching from local saved DB ticker data  .. \n",
      "fetched from local saved DB ticker data  .. \n",
      " Processing ...  EICHERMOT.NS\n",
      "fetching from local saved DB ticker data  .. \n",
      "fetched from local saved DB ticker data  .. \n",
      " Processing ...  INFY.NS\n",
      "fetching from local saved DB ticker data  .. \n",
      "fetched from local saved DB ticker data  .. \n",
      " Processing ...  INFY.NS\n",
      "fetching from local saved DB ticker data  .. \n",
      "fetched from local saved DB ticker data  .. \n",
      " Processing ...  INFY.NS\n",
      "fetching from local saved DB ticker data  .. \n",
      "fetched from local saved DB ticker data  .. \n",
      " Processing ...  INFY.NS\n",
      "fetching from local saved DB ticker data  .. \n",
      "fetched from local saved DB ticker data  .. \n",
      " Processing ...  INFY.NS\n",
      "fetching from local saved DB ticker data  .. \n",
      "fetched from local saved DB ticker data  .. \n",
      " Processing ...  WIPRO.NS\n",
      "fetching from local saved DB ticker data  .. \n",
      "fetched from local saved DB ticker data  .. \n",
      " Processing ...  WIPRO.NS\n",
      "fetching from local saved DB ticker data  .. \n",
      "fetched from local saved DB ticker data  .. \n",
      " Processing ...  WIPRO.NS\n",
      "fetching from local saved DB ticker data  .. \n",
      "fetched from local saved DB ticker data  .. \n",
      " Processing ...  WIPRO.NS\n",
      "fetching from local saved DB ticker data  .. \n",
      "fetched from local saved DB ticker data  .. \n",
      " Processing ...  WIPRO.NS\n",
      "fetching from local saved DB ticker data  .. \n",
      "fetched from local saved DB ticker data  .. \n",
      " Processing ...  TECHM.NS\n",
      "fetching from local saved DB ticker data  .. \n",
      "fetched from local saved DB ticker data  .. \n",
      " Processing ...  TECHM.NS\n",
      "fetching from local saved DB ticker data  .. \n",
      "fetched from local saved DB ticker data  .. \n",
      " Processing ...  TECHM.NS\n",
      "fetching from local saved DB ticker data  .. \n",
      "fetched from local saved DB ticker data  .. \n",
      " Processing ...  TECHM.NS\n",
      "fetching from local saved DB ticker data  .. \n",
      "fetched from local saved DB ticker data  .. \n",
      " Processing ...  TECHM.NS\n",
      "fetching from local saved DB ticker data  .. \n",
      "fetched from local saved DB ticker data  .. \n",
      " Processing ...  JSWSTEEL.NS\n",
      "fetching from local saved DB ticker data  .. \n",
      "fetched from local saved DB ticker data  .. \n",
      " Processing ...  JSWSTEEL.NS\n",
      "fetching from local saved DB ticker data  .. \n",
      "fetched from local saved DB ticker data  .. \n",
      " Processing ...  JSWSTEEL.NS\n",
      "fetching from local saved DB ticker data  .. \n",
      "fetched from local saved DB ticker data  .. \n",
      " Processing ...  JSWSTEEL.NS\n",
      "fetching from local saved DB ticker data  .. \n",
      "fetched from local saved DB ticker data  .. \n",
      " Processing ...  JSWSTEEL.NS\n",
      "fetching from local saved DB ticker data  .. \n",
      "fetched from local saved DB ticker data  .. \n",
      " Processing ...  MANAPPURAM.NS\n",
      "fetching from local saved DB ticker data  .. \n",
      "fetched from local saved DB ticker data  .. \n",
      " Processing ...  MANAPPURAM.NS\n",
      "fetching from local saved DB ticker data  .. \n",
      "fetched from local saved DB ticker data  .. \n",
      " Processing ...  MANAPPURAM.NS\n",
      "fetching from local saved DB ticker data  .. \n",
      "fetched from local saved DB ticker data  .. \n",
      " Processing ...  MANAPPURAM.NS\n",
      "fetching from local saved DB ticker data  .. \n",
      "fetched from local saved DB ticker data  .. \n",
      " Processing ...  MANAPPURAM.NS\n",
      "fetching from local saved DB ticker data  .. \n",
      "fetched from local saved DB ticker data  .. \n",
      " Processing ...  DRREDDY.NS\n",
      "fetching from local saved DB ticker data  .. \n",
      "fetched from local saved DB ticker data  .. \n",
      " Processing ...  DRREDDY.NS\n",
      "fetching from local saved DB ticker data  .. \n",
      "fetched from local saved DB ticker data  .. \n",
      " Processing ...  DRREDDY.NS\n",
      "fetching from local saved DB ticker data  .. \n",
      "fetched from local saved DB ticker data  .. \n",
      " Processing ...  DRREDDY.NS\n",
      "fetching from local saved DB ticker data  .. \n",
      "fetched from local saved DB ticker data  .. \n",
      " Processing ...  DRREDDY.NS\n",
      "fetching from local saved DB ticker data  .. \n",
      "fetched from local saved DB ticker data  .. \n",
      " top scores ....                        ticker  scores_2d  scores_5d  scores_1mo  scores_1y  \\\n",
      "DRREDDY.NS        DRREDDY.NS  35.627569  35.627569   35.627569  35.627569   \n",
      "DEEPAKNTR.NS    DEEPAKNTR.NS  35.572180  35.572180   35.572180  35.572180   \n",
      "EICHERMOT.NS    EICHERMOT.NS  29.614644  29.614644   29.614644  29.614644   \n",
      "MUTHOOTFIN.NS  MUTHOOTFIN.NS  24.771313  24.771313   24.771313  24.771313   \n",
      "TECHM.NS            TECHM.NS  24.328202  24.328202   24.328202  24.328202   \n",
      "INFY.NS              INFY.NS  21.695208  21.695208   21.695208  21.695208   \n",
      "ICICIPRULI.NS  ICICIPRULI.NS  17.938469  17.938469   17.938469  17.938469   \n",
      "WIPRO.NS            WIPRO.NS  17.339624  17.339624   17.339624  17.339624   \n",
      "MANAPPURAM.NS  MANAPPURAM.NS  15.591921  15.591921   15.591921  15.591921   \n",
      "BAJAJ-AUTO.NS  BAJAJ-AUTO.NS  11.565127  11.565127   11.565127  11.565127   \n",
      "BAJAJELEC.NS    BAJAJELEC.NS   2.652648   2.652648    2.652648   2.652648   \n",
      "JSWSTEEL.NS      JSWSTEEL.NS  -1.978890  -1.978890   -1.978890  -1.978890   \n",
      "MUTHOOTCAP.NS  MUTHOOTCAP.NS  -4.007287  -4.007287   -4.007287  -4.007287   \n",
      "COALINDIA.NS    COALINDIA.NS  -4.899087  -4.899087   -4.899087  -4.899087   \n",
      "\n",
      "               scores_5y  \n",
      "DRREDDY.NS     35.627569  \n",
      "DEEPAKNTR.NS   35.572180  \n",
      "EICHERMOT.NS   29.614644  \n",
      "MUTHOOTFIN.NS  24.771313  \n",
      "TECHM.NS       24.328202  \n",
      "INFY.NS        21.695208  \n",
      "ICICIPRULI.NS  17.938469  \n",
      "WIPRO.NS       17.339624  \n",
      "MANAPPURAM.NS  15.591921  \n",
      "BAJAJ-AUTO.NS  11.565127  \n",
      "BAJAJELEC.NS    2.652648  \n",
      "JSWSTEEL.NS    -1.978890  \n",
      "MUTHOOTCAP.NS  -4.007287  \n",
      "COALINDIA.NS   -4.899087  \n"
     ]
    }
   ],
   "source": [
    "# get stored data from DB into a DF and do processing with it\n",
    "# df = df_from_db('BAJAJFINSV.NS', '1y')\n",
    "# print('1y data ... fetched df from db ', df.tail(1).to_json())\n",
    "\n",
    "# df_scores = pd.DataFrame([],columns=['ticker', 'scores_2d','scores_5d','scores_1mo','scores_1y','scores_5y'])\n",
    "\n",
    "\n",
    "df_scores = pd.DataFrame({'ticker': [], 'scores_2d': [], 'scores_5d': [],'scores_1mo': [],'scores_1y': [],'scores_5y': [] }, columns=['ticker', 'scores_2d','scores_5d','scores_1mo','scores_1y','scores_5y'])\n",
    "print(df_scores)\n",
    "# df_scores.reindex()\n",
    "for _ticker in filtered_companies:\n",
    "    df_5y = get_technical_data(_ticker, duration='5y', tf='1w')\n",
    "    df_1y = get_technical_data(_ticker, duration='1y', tf='1d')\n",
    "    df_1mo = get_technical_data(_ticker, duration='1mo', tf='1d')\n",
    "    df_5d = get_technical_data(_ticker, duration='5d', tf='5min')\n",
    "    df_2d = get_technical_data(_ticker, duration='3d', tf='5min')\n",
    "    \n",
    "    scores_5y = df_5y.tail(1).apply(lambda x: compute_score(x), axis=1)\n",
    "    scores_1y = df_1y.tail(1).apply(lambda x: compute_score(x), axis=1)\n",
    "    scores_1mo = df_1mo.tail(1).apply(lambda x: compute_score(x), axis=1)\n",
    "    scores_2d = df_2d.tail(1).apply(lambda x: compute_score(x), axis=1)\n",
    "    scores_5d = df_5d.tail(1).apply(lambda x: compute_score(x), axis=1)\n",
    "    df_scores.loc[_ticker] = [ _ticker, scores_2d.values[0], scores_5d.values[0], scores_1mo.values[0], scores_1y.values[0], scores_5y.values[0]]\n",
    "# Sort and get top most values\n",
    " \n",
    "top_scores = df_scores.sort_values(by=['scores_2d', 'scores_5d', 'scores_1mo', 'scores_1y', 'scores_5y'], ascending=False).head(15)\n",
    "print(' top scores .... ', top_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjust the saved data (different durations and time spans) upon different time intervals\n",
    "# 5y data - 1d wise tick :: upon each 1 day,\n",
    "    # adjust the Arctic version to be T1 + 1hr to T2 + 1hr(now) data and corresponding TA data\n",
    "# 1y data - 1d wise tick :: upon each 1 day,\n",
    "    # adjust the Arctic version to be T1 + 1hr to T2 + 1hr(now) data and corresponding TA data\n",
    "# 1mo data - 5min wise tick :: upon each 5 mins,\n",
    "    # adjust the Arctic version to be T1 + 15mins to T2 + 15mins(now) data and corresponding TA data\n",
    "# 5d data - min wise tick :: upon each 5 mins,\n",
    "    # adjust the Arctic version to be T1 + 5mins to T2 + 5mins(now) data and corresponding TA data\n",
    "# 2d data - min wise tick :: upon each 5 mins,\n",
    "    # adjust the Arctic version to be T1 + 5mins to T2 + 5mins(now) data and corresponding TA data\n",
    "# 1d data - min wise tick :: upon each 5 mins, \n",
    "    # adjust the Arctic version to be T1 + 5mins to T2 + 5mins(now) data and corresponding TA data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit ('venv': venv)",
   "language": "python",
   "name": "python379jvsc74a57bd0066e8cbcad4da590cee410d50769781f2dd34998db2d5815197c4294647d3084"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
